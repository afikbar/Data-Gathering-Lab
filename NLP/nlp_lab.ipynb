{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.elasticsearch:elasticsearch-hadoop:7.4.2 pyspark-shell'\n",
    "\n",
    "# IP = 'da2019w-1019.eastus.cloudapp.azure.com'\n",
    "IP = '10.0.0.25'\n",
    "# GOOGLE_API_KEY = 'AIzaSyBSp6bqrg9ijhLKXAkn5Rt4BrPpnnpv2d8'\n",
    "HERE_API_KEY = 'TarqgkWPPRHbWkLVZWCz2VAGJVHWj_B18ii-yO5pyZo'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pyspark.sql.window import Window\n",
    "import requests\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT\")\n",
    "\n",
    "es = Elasticsearch([{'host': IP}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_elastic(index, query=\"\", scroll_size=\"10000\", array_field=\"\"):\n",
    "    if not es.indices.exists(index):\n",
    "        raise Exception(\"Index doesn't exist!\")\n",
    "\n",
    "    return spark.read\\\n",
    "                .format(\"org.elasticsearch.spark.sql\")\\\n",
    "                .option(\"es.nodes.wan.only\",\"true\")\\\n",
    "                .option(\"es.port\",\"9200\")\\\n",
    "                .option(\"es.nodes\",IP)\\\n",
    "                .option(\"es.nodes.client.only\", \"false\")\\\n",
    "                .option(\"pushdown\", \"true\")\\\n",
    "                .option(\"es.query\", query)\\\n",
    "                .option(\"es.scroll.size\", scroll_size)\\\n",
    "                .option(\"es.scroll.keepalive\", \"120m\")\\\n",
    "                .option(\"es.read.field.as.array.include\", array_field)\\\n",
    "                .load(index)\n",
    "\n",
    "        \n",
    "DEFUALT_SCEHMA = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"actualDelay\" : { \"type\": \"long\" },\n",
    "            \"areaId\" : { \"type\": \"long\" },\n",
    "            \"areaId1\" : { \"type\": \"long\" },\n",
    "            \"areaId2\" : { \"type\": \"long\" },\n",
    "            \"areaId3\" : { \"type\": \"long\" },\n",
    "            \"atStop\" : { \"type\": \"boolean\" },\n",
    "            \"busStop\" : { \"type\": \"long\" },\n",
    "            \"congestion\" : { \"type\": \"boolean\" },\n",
    "            \"gridID\" : { \"type\": \"keyword\" },\n",
    "            \"journeyPatternId\" : { \"type\": \"keyword\" },\n",
    "            \"lineId\" : { \"type\": \"keyword\" },\n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "            \"timestamp\" : { \"type\": \"date\", \"format\" : \"epoch_millis\" },\n",
    "            \"vehicleId\" : { \"type\": \"long\" },\n",
    "            \"dateTime\" : { \"type\": \"date\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def write_to_elastic(df, index: str, settings=DEFUALT_SCEHMA, append=True):\n",
    "    if es.indices.exists(index) and not append:\n",
    "        es.indices.delete(index=index)\n",
    "    \n",
    "    es.indices.create(index=index, ignore=400, body=settings)\n",
    "\n",
    "    df.write.format(\"org.elasticsearch.spark.sql\")\\\n",
    "        .option(\"es.resource\", index)\\\n",
    "        .option(\"es.nodes.wan.only\",\"true\")\\\n",
    "        .option(\"es.port\",\"9200\")\\\n",
    "        .option(\"es.nodes\",IP)\\\n",
    "        .option(\"es.nodes.client.only\", \"false\")\\\n",
    "        .save()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_centroids(df):\n",
    "    centroid_df = df.groupBy('busStop')\\\n",
    "                    .agg(F.mean(df.coordinates[0]).alias('centroid_longitude'), \n",
    "                            F.mean(df.coordinates[1]).alias('centroid_latitude'))\n",
    "\n",
    "    centroid_df = centroid_df.withColumn(\"coordinates\", F.array('centroid_longitude', 'centroid_latitude'))\\\n",
    "                                .drop('centroid_longitude', 'centroid_latitude')\n",
    "    return centroid_df\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "@F.udf(\"float\")\n",
    "def get_distance(coord_a, coord_b):\n",
    "    longit_a, latit_a = coord_a\n",
    "    longit_b, latit_b = coord_b\n",
    "    if None in [longit_a, latit_a, longit_b, latit_b]:\n",
    "        return 9999\n",
    "    # Transform to radians\n",
    "    longit_a, latit_a, longit_b, latit_b = map(radians, [longit_a,  latit_a, longit_b, latit_b])\n",
    "    dist_longit = longit_b - longit_a\n",
    "    dist_latit = latit_b - latit_a\n",
    "    # Calculate area\n",
    "    area = sin(dist_latit/2)**2 + cos(latit_a) * cos(latit_b) * sin(dist_longit/2)**2\n",
    "    # Calculate the central angle\n",
    "    central_angle = 2 * asin(sqrt(area))\n",
    "    radius = 6371\n",
    "    # Calculate Distance\n",
    "    distance = central_angle * radius\n",
    "    return abs(round(distance, 4))\n",
    "\n",
    "def add_distance_to_centroid(centroid_df, stop_df, drop_centroid_col=True):\n",
    "    c_df = centroid_df.selectExpr(\"coordinates as c_coordinates\", \"busStop as c_busStop\")\n",
    "    left_join = stop_df.join(c_df, stop_df['busStop'] == c_df['c_busStop'], how='inner')\n",
    "    res = left_join.withColumn('distance', get_distance(left_join.c_coordinates, left_join.coordinates)).drop('c_busStop')\n",
    "    if drop_centroid_col:\n",
    "        return res.drop('c_coordinates')\n",
    "    return res\n",
    "\n",
    "@F.udf(ArrayType(DoubleType()))\n",
    "def merge_coordinates(longitude, latitude):\n",
    "    return [float(longitude), float(latitude)]\n",
    "\n",
    "@F.udf(\"float\")\n",
    "def normalize_text_distance(name1, name2, distance):\n",
    "    return distance / max(len(name1), len(name2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BusStop Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busStops = requests.get(f'https://data.smartdublin.ie/cgi-bin/rtpi/busstopinformation').json()['results']\n",
    "columns_to_keep = ['stopid', 'displaystopid', 'shortname', 'shortnamelocalized',\n",
    "                   'fullname', 'fullnamelocalized', 'longitude', 'latitude']\n",
    "stops_df = spark.createDataFrame(pd.DataFrame(busStops).loc[:,columns_to_keep])\n",
    "stops_df = stops_df.withColumn('coordinates', merge_coordinates(stops_df.longitude, stops_df.latitude)).drop('longitude', 'latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_index = 'stop-information-index'\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"stopid\" : { \"type\": \"long\" },\n",
    "            \"displaystopid\" : { \"type\": \"string\" },\n",
    "            \"shortname\" : { \"type\": \"string\" },\n",
    "            \"shortnamelocalized\" : { \"type\": \"string\" },\n",
    "            \"fullname\" : { \"type\": \"string\" },\n",
    "            \"fullnamelocalized\" : { \"type\": \"string\" },\n",
    "            \"coordinates\" : {\"type\" : 'geo_point'}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "write_to_elastic(stops_df, stops_index, settings, append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where am I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_distance(s1,s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1\n",
    "    distances = range(len(s1) + 1)\n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1])\n",
    "            else:\n",
    "                newDistances.append(1 + min((distances[index1],\n",
    "                                             distances[index1+1],\n",
    "                                             newDistances[-1])))\n",
    "        distances = newDistances\n",
    "    return distances[-1]\n",
    "\n",
    "@F.udf('float')\n",
    "def get_text_distance(station_name, reverse_gecode):\n",
    "    lev_dist = 2**10\n",
    "    \n",
    "    if reverse_gecode and station_name:\n",
    "        lev_dist = min([lev_distance(station_name, address)/max(len(station_name), len(address)) for address in reverse_gecode if address])\n",
    "    return lev_dist\n",
    "\n",
    "\n",
    "STOPWORDS = ['avenue', 'ave', 'blvd', 'boulevard', 'box', 'cir', 'court', 'ct', 'drive', 'dr', 'lane', 'ln', 'loop', 'lp', 'pl', 'place', 'po', 'pob', 'pt', 'rd', 'road', 'route', 'rr', 'rte', 'rural', 'sq', 'st', 'ste', 'street', 'suit', 'trl', 'way', 'wy']\n",
    "\n",
    "def extract_address(result):\n",
    "    address = []\n",
    "    try:\n",
    "        address = result['Location']['Address']['Street']\n",
    "    except:\n",
    "        address = result['Location']['Address']['Label']\n",
    "    return ' '.join(filter(lambda word: word.lower().rstrip('.') not in STOPWORDS, address.split()))\n",
    "\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def reverse_gecode(coords):\n",
    "    lng, lat = coords\n",
    "    params = {'prox' : f\"{lat}, {lng}, 5\", 'mode' : 'retrieveAddresses', 'apiKey' : HERE_API_KEY}\n",
    "    results = requests.get(\"https://reverse.geocoder.ls.hereapi.com/6.2/reversegeocode.json\", params=params)\\\n",
    "                                                                                    .json()['Response']['View'][0]['Result']\n",
    "    addresses = list(set(map(extract_address, results)))\n",
    "    \n",
    "    return addresses\n",
    "\n",
    "\n",
    "@F.udf(BooleanType())\n",
    "def is_approx_near(coords_a, coords_b, decimal=5):\n",
    "    lng_a, lat_a = coords_a\n",
    "    lng_b, lat_b = coords_b\n",
    "\n",
    "    return (round(lng_a, decimal) == round(lng_b, decimal)) and (round(lat_a, decimal) == round(lat_b, decimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stop_df = read_elastic('agg1-coords-index')\\\n",
    "                .withColumn('reverse_gecode', reverse_gecode(F.col('coordinates')))\n",
    "                # .withColumnRenamed('coordinates', 'agg_coords')\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {    \n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "            \"reverse_gecode\" : { \"type\": \"keyword\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# Was \"reverse-gecode-index\"\n",
    "write_to_elastic(agg_stop_df, 'agg1-street-index', settings= settings, append= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stop_df =  read_elastic(\"agg1-street-index\", array_field=\"reverse_gecode\")\\\n",
    "                .withColumnRenamed('coordinates', 'agg_coords')\n",
    "                # .withColumn('reverse_gecode', F.array_distinct(\"reverse_gecode\"))\n",
    "\n",
    "stop_df = read_elastic('stop-index')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reverse_gecode_df = stop_df.join(agg_stop_df, \n",
    "                                    (F.round(F.element_at(stop_df.coordinates, 1), 5) == F.round(F.element_at(agg_stop_df.agg_coords, 1), 5)) &\n",
    "                                    (F.round(F.element_at(stop_df.coordinates, 2), 5) == F.round(F.element_at(agg_stop_df.agg_coords, 2), 5)),\n",
    "                                    how='left').drop('agg_coords')\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"actualDelay\" : { \"type\": \"long\" },\n",
    "            \"areaId\" : { \"type\": \"long\" },\n",
    "            \"areaId1\" : { \"type\": \"long\" },\n",
    "            \"areaId2\" : { \"type\": \"long\" },\n",
    "            \"areaId3\" : { \"type\": \"long\" },\n",
    "            \"atStop\" : { \"type\": \"boolean\" },\n",
    "            \"busStop\" : { \"type\": \"long\" },\n",
    "            \"congestion\" : { \"type\": \"boolean\" },\n",
    "            \"gridID\" : { \"type\": \"keyword\" },\n",
    "            \"journeyPatternId\" : { \"type\": \"keyword\" },\n",
    "            \"lineId\" : { \"type\": \"keyword\" },\n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "            \"timestamp\" : { \"type\": \"date\", \"format\" : \"epoch_millis\" },\n",
    "            \"vehicleId\" : { \"type\": \"long\" },\n",
    "            \"dateTime\" : { \"type\": \"date\" },\n",
    "            \"reverse_gecode\" : { \"type\": \"keyword\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "write_to_elastic(reverse_gecode_df, 'reverse-gecode-index', settings=settings, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_gecode_df = read_elastic('reverse-gecode-index', array_field=\"reverse_gecode\")\n",
    "\n",
    "stop_info_df = read_elastic('stop-information-index').select('stopid', 'shortname')\n",
    "\n",
    "joined_df = reverse_gecode_df\\\n",
    "                .join(stop_info_df, reverse_gecode_df['busStop'] == stop_info_df['stopid'], how='inner')\\\n",
    "                .withColumn('lev_distance', get_text_distance(F.col('shortname'), F.col('reverse_gecode')))\\\n",
    "                .drop('stopid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"actualDelay\" : { \"type\": \"long\" },\n",
    "            \"areaId\" : { \"type\": \"long\" },\n",
    "            \"areaId1\" : { \"type\": \"long\" },\n",
    "            \"areaId2\" : { \"type\": \"long\" },\n",
    "            \"areaId3\" : { \"type\": \"long\" },\n",
    "            \"atStop\" : { \"type\": \"boolean\" },\n",
    "            \"busStop\" : { \"type\": \"long\" },\n",
    "            \"congestion\" : { \"type\": \"boolean\" },\n",
    "            \"gridID\" : { \"type\": \"keyword\" },\n",
    "            \"journeyPatternId\" : { \"type\": \"keyword\" },\n",
    "            \"lineId\" : { \"type\": \"keyword\" },\n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "            \"timestamp\" : { \"type\": \"date\", \"format\" : \"epoch_millis\" },\n",
    "            \"vehicleId\" : { \"type\": \"long\" },\n",
    "            \"dateTime\" : { \"type\": \"date\" },\n",
    "            \"shortname\" : { \"type\" : \"keyword\" },\n",
    "            \"reverse_gecode\" : { \"type\": \"keyword\" },\n",
    "            \"lev_distance\" : { \"type\": \"double\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "write_to_elastic(joined_df, 'lev-dist-index', settings=settings, append= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by Levenshtien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df = read_elastic('lev-dist-index', array_field=\"reverse_gecode\")\n",
    "\n",
    "filter_stop = stop_df.filter(\"lev_distance < 0.2\").drop('lev_distance')\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"actualDelay\" : { \"type\": \"long\" },\n",
    "            \"areaId\" : { \"type\": \"long\" },\n",
    "            \"areaId1\" : { \"type\": \"long\" },\n",
    "            \"areaId2\" : { \"type\": \"long\" },\n",
    "            \"areaId3\" : { \"type\": \"long\" },\n",
    "            \"atStop\" : { \"type\": \"boolean\" },\n",
    "            \"busStop\" : { \"type\": \"long\" },\n",
    "            \"congestion\" : { \"type\": \"boolean\" },\n",
    "            \"gridID\" : { \"type\": \"keyword\" },\n",
    "            \"journeyPatternId\" : { \"type\": \"keyword\" },\n",
    "            \"lineId\" : { \"type\": \"keyword\" },\n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "            \"timestamp\" : { \"type\": \"date\", \"format\" : \"epoch_millis\" },\n",
    "            \"vehicleId\" : { \"type\": \"long\" },\n",
    "            \"dateTime\" : { \"type\": \"date\" },\n",
    "            \"shortname\" : { \"type\" : \"keyword\" },\n",
    "            \"reverse_gecode\" : { \"type\": \"keyword\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "write_to_elastic(filter_stop, 'filter-lev-dist-index', settings=settings, append=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Centroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = read_elastic('filter-lev-dist-index')\n",
    "stop_df = read_elastic('lev-dist-index', array_field=\"reverse_gecode\")\n",
    "\n",
    "filtered_df = stop_df.filter(\"lev_distance < 0.5\").drop('lev_distance')\n",
    "\n",
    "filtered_df_centroids = calculate_centroids(filtered_df.select(\"busStop\", \"coordinates\"))\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"busStop\" : { \"type\": \"long\" },\n",
    "            \"coordinates\" : { \"type\": \"geo_point\" },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "write_to_elastic(filtered_df_centroids, index=\"filter-0.5-lev-dist-centroid-index\", settings=settings, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE Value for Centroid is 0.2739573164432086\n"
     ]
    }
   ],
   "source": [
    "stop_centroid_df = read_elastic(\"filter-0.5-lev-dist-centroid-index\")\n",
    "true_coord_df = read_elastic('true-centroid-index')\n",
    "\n",
    "eval_df = true_coord_df.withColumnRenamed('coordinates', 'true_coordinates')\n",
    "eval_df = eval_df.join(stop_centroid_df, on='busStop', how='inner').withColumnRenamed('coordinates', 'centroid_coordinates')\n",
    "\n",
    "mse_centroid = eval_df.agg(F.mean(F.pow(get_distance(eval_df.true_coordinates, eval_df.centroid_coordinates), 2)).alias('mse')).collect()[0]['mse']\n",
    "\n",
    "print(f\"The MSE Value for Centroid is {mse_centroid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df = read_elastic('stop-information-index')\n",
    "true_coords = read_elastic('true-coord-index').select('busStop')\n",
    "stops_df = stops_df.join(true_coords, stops_df.stopid == true_coords.busStop, how='inner').drop('stopid')\n",
    "stops_df = stops_df.select('busStop', 'fullname', 'coordinates').where(stops_df.fullname != '').orderBy('busStop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df1 = stops_df.\\\n",
    "                withColumnRenamed('busStop', 'busStop1').\\\n",
    "                withColumnRenamed('fullname', 'fullname1').\\\n",
    "                withColumnRenamed('coordinates', 'coordinates1')\n",
    "stops_df2 = stops_df.\\\n",
    "                withColumnRenamed('busStop', 'busStop2').\\\n",
    "                withColumnRenamed('fullname', 'fullname2').\\\n",
    "                withColumnRenamed('coordinates', 'coordinates2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_distances = stops_df1.crossJoin(stops_df2)\n",
    "stops_distances = stops_distances.\\\n",
    "        withColumn('distance', get_distance(F.col('coordinates1'), F.col('coordinates2'))).\\\n",
    "        withColumn('text_distance', F.levenshtein(F.col('fullname1'), F.col('fullname2')))\n",
    "        \n",
    "w = Window.partitionBy(\"busStop1\")\n",
    "scaled_result = (F.col(\"distance\") - F.min(\"distance\").over(w)) / (F.max(\"distance\").over(w) - F.min(\"distance\").over(w))\n",
    "stops_distances = stops_distances.withColumn(\"scaled_distance\", scaled_result).\\\n",
    "            withColumn(\"normalized_text_distance\", normalize_text_distance(F.col('fullname1'), F.col('fullname2'), F.col('text_distance')))\n",
    "stops_distances = stops_distances.select('busStop1', 'busStop2', 'text_distance', 'normalized_text_distance', 'distance', 'scaled_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_index = 'stops-distances-index'\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"busStop1\" : { \"type\": \"long\" },\n",
    "            \"busStop2\" : { \"type\": \"long\" },\n",
    "            \"text_distance\" : { \"type\": \"double\" },\n",
    "            \"distance\" : { \"type\": \"double\" },\n",
    "            \"normalized_text_distance\" : { \"type\": \"double\" },\n",
    "            \"scaled_distance\" : { \"type\": \"double\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "write_to_elastic(stops_distances, distances_index, settings, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_index = 'stops-distances-index'\n",
    "stop_num = 7207\n",
    "stop = read_elastic(index=distances_index).where(F.col('busStop1') == stop_num).toPandas()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.regplot(stop.scaled_distance, stop.normalized_text_distance)\n",
    "plt.xlabel('Scaled Distance')\n",
    "plt.ylabel('Normaliazed Levenshtein Distance')\n",
    "plt.title(f'Stop Number {stop_num}', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df = read_elastic('stop-information-index')\n",
    "true_coords = read_elastic('true-coord-index').select('busStop')\n",
    "stops_df = stops_df.\\\n",
    "    join(true_coords, stops_df.stopid == true_coords.busStop, how='inner').\\\n",
    "    drop('stopid').\\\n",
    "    where(stops_df.shortnamelocalized != '').\\\n",
    "    orderBy('busStop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = stops_df.select('busStop', 'shortname').withColumnRenamed('busStop', 'busStop1')\n",
    "irish = stops_df.select('busStop', 'shortnamelocalized').withColumnRenamed('busStop', 'busStop2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_lang = english.crossJoin(irish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_lang = cross_lang.\\\n",
    "        withColumn('text_distance', F.levenshtein(F.col('shortname'), F.col('shortnamelocalized'))).\\\n",
    "        withColumn(\"normalized_text_distance\", normalize_text_distance(F.col('shortname'), F.col('shortnamelocalized'), F.col('text_distance')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cross_lang = cross_lang.groupby('busStop1').pivot('busStop2').agg(F.first('normalized_text_distance'))\n",
    "pivot_cross_lang = pivot_cross_lang.orderBy('busStop1', ascending=True).drop('busStop1').toPandas()\n",
    "pivot_cross_lang = 1 - pivot_cross_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove cell\n",
    "pivot_cross_lang = 1 - pd.read_pickle('lang.pkl')\n",
    "num_stops = pivot_cross_lang.shape[0]\n",
    "best = num_stops * np.diag(pivot_cross_lang) - pivot_cross_lang.sum(axis=1)\n",
    "s = np.array(best.sort_values(ascending=False).index)\n",
    "pivot_cross_lang = pivot_cross_lang.iloc[s,s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(pivot_cross_lang.iloc[:1001,:1001], cmap=plt.cm.Blues)\n",
    "plt.xlabel('Irish busStop Name')\n",
    "plt.ylabel('English busStop Name')\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.title('Levenshtein Similarity', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
