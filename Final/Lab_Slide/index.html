<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Data Gathering &amp; Management</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="node_modules/reveal.js/css/reveal.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme"><!--This CSS is generated by the Asciidoctor-Reveal.js converter to further integrate AsciiDoc's existing semantic with Reveal.js--><style type="text/css">.reveal div.right {
  float: right;
}

/* callouts */
.conum[data-value] {display:inline-block;color:#fff!important;background-color:rgba(50,150,50,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}</style><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><link href="node_modules/reveal.js/lib/css/zenburn.css" rel="stylesheet"><script>var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? "node_modules/reveal.js/css/print/pdf.css" : "node_modules/reveal.js/css/print/paper.css";
document.getElementsByTagName( 'head' )[0].appendChild( link );</script><!--[if lt IE 9]><script src="node_modules/reveal.js/lib/js/html5shiv.js"></script><![endif]--></head><body><div class="reveal"><div class="slides"><section class="title" data-state="title" data-transition="zoom"><h1>Data Gathering &amp; Management</h1><div class="preamble"><div class="paragraph"><p>Final Task</p></div></div></section>
<section id="_the_data"><h2>The Data</h2><div class="paragraph"><p><code>230 million</code> records from bus sensors within Dublin, between July 2017 to September 2018.</p></div></section>
<section id="_extract_transform_load"><h2>Extract, Transform, Load.</h2><div class="ulist step"><ul><li class="fragment"><p><em>Apache Spark</em>&#8482; as processing framework.</p></li><li class="fragment"><p>We&#8217;ve filtered records that doesn&#8217;t correspond with a specified route (line @ station).</p></li><li class="fragment"><p>An additional feature was added, <code>direction</code>, which specifies the direction of movement (slope).</p></li><li class="fragment"><p>All the data was loaded onto <em>Elasticsearch</em> &#x1f499; cluster.</p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p>Data integration explained later</p></li><li><p>direction was added for UKMeans</p></li></ul></div></aside></section>
<section id="_uncertain_data"><h2>Uncertain data</h2><div class="paragraph"><p>Our task is to shed some light over the data uncertainty.<br>
<code>busStop</code> &amp; <code>atStop</code> are both prime suspects.</p></div>
<div class="imageblock" style=""><img src="../images/stop-415-heatmap.png" alt="stop 415 heatmap" width="70%"></div>
<aside class="notes"><div class="ulist"><ul><li><p>Bus Stop 415 Heatmap</p></li><li><p>we suspect busStop &amp; atStop was calculated and not reported</p></li></ul></div></aside></section>
<section><section id="_uncertain_real_time"><h2>Uncertain, Real-Time</h2><div class="ulist step"><ul><li class="fragment"><p>We intend to estimate the <strong>true</strong> location of a bus stop, from the observed data.<br></p></li><li class="fragment"><p>While reading a stream, we will <em>fix</em> <code>busStop</code> to the closest station (which is <em>on-route</em>).<br></p></li><li class="fragment"><p>After each batch, we will update our estimations with the <em>new</em> data.</p></li><li class="fragment"><p>To avoid extra noise - we will set <code>atStop</code> to all reports within <code>50 meters</code> from it&#8217;s <em>fixed</em> station.</p></li></ul></div><aside class="notes"><div class="ulist"><ul><li><p>Resembles EM</p></li><li><p>atStop fixing will not affect estimation updates, to allow bias</p></li></ul></div></aside></section><section id="_estimations"><h2>Estimations</h2><div class="paragraph"><p>For all estimations, we&#8217;ve used only reports with <code>atStop = True</code>.</p></div>
<div class="ulist step"><ul><li class="fragment"><p>Simple centroid</p></li><li class="fragment"><p>K-Means</p></li><li class="fragment"><p>UK-Means (line-moving)</p></li><li class="fragment"><p>UK-Means (free-moving)</p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p>Explain stuff here</p></li></ul></div></aside></section><section id="_k_means_adaptation"><h2>K-Means adaptation</h2><div class="paragraph"><p>The data is very dense.<br>
&#8594; bus reports near stations that aren&#8217;t on their route.</p></div>
<div class="paragraph"><p>Instead of <strong>restricting</strong> K-Means algorithm, we will partition the data by <code>JourneyPatternId</code>.<br>
This will allow convergence only to stations along the route.</p></div>
<aside class="notes"><div class="ulist"><ul><li><p>KMeans will label lines that are close to centroids which isn&#8217;t on their route.</p></li></ul></div></aside></section><section id="_uk_means"><h2>UK-Means</h2><div class="paragraph"><p>Following our presented article:<br>
(<code>Uncertain Data Mining: An Example in Clustering Location Data</code>)<br>
We&#8217;ve implemented Uncertain data clustering algorithm, which targets moving object uncertainty.</p></div>
<div class="imageblock" style=""><img src="../images/ukmeans.png" alt="ukmeans"></div>
<aside class="notes"><div class="ulist"><ul><li><p>Moving - Directed (line) &amp; Free (radius)</p></li></ul></div></aside></section><section id="_uk_means_adaptation"><h2>UK-Means adaptation</h2><div class="ulist step"><ul><li class="fragment"><p><strong>Line-moving uncertainty:</strong><br>
We&#8217;ve used the calculated <code>direction</code> at each <code>atStop</code> report as the line&#8217;s slope.<br>
The length was determined as <code>50 meters</code>.</p></li><li class="fragment"><p><strong>Free-moving uncertainty:</strong><br>
The radius was defined to <code>50 meters</code>.<br>
underlying assumption is uniform distribution around the centroid.</p></li></ul></div></section></section>
<section id="_you_cant_handle_the_truth"><h2>YOU CAN&#8217;T HANDLE THE TRUTH!</h2></section>
<section id="_these_are_not_the_droids_you_are_looking_for"><h2>These are not the droids you are looking for&#8230;&#8203;</h2></section>
<section id="_but_how_can_we_really_know"><h2>But, how can we REALLY know?</h2><div class="imageblock" style=""><img src="../images/search.gif" alt="search" width="50%"></div>
<div class="paragraph"><p>To evaluate our predictions, we&#8217;ve accessed RTPI API service to collect the <strong>true</strong> location of each bus stop in our data.</p></div></section>
<section id="_textual_data_integration"><h2>Textual Data Integration</h2><div class="ulist"><ul><li><p>We&#8217;ve used &#8220;HERE Maps&#8221; REST-API to <em>reverse geocode</em> (coordinates &#8594; street address) all <code>atStop</code> observations from the data (<code>50 million</code>).</p></li><li><p>Then we&#8217;ve added (from RTPi) all the bus stations names, both in English &amp; Gaeilge (Irish).</p></li></ul></div>
<div class="paragraph"><p>We plan to calculate the <em>distance</em> between the reported bus station name, and the actual street address derived from the coordinates.</p></div>
<aside class="notes"><div class="ulist"><ul><li><p>The mentioned API has a strong limitation of 50 requests per second, if we were to retrieve all street addresses, it would&#8217;ve take two weeks.</p></li><li><p>We were able to reduce the amount of required requests from the API to <code>300,000</code>, by reducing the coordinates precision to 5 decimal degrees (<code>~1 squared meter</code> error).</p></li><li><p>This is under an assumption that most bus stations names are determined by the street they are located in.</p></li></ul></div></aside></section>
<section id="_text_distance"><h2>Text Distance</h2><div class="paragraph"><p>We used Levenshtien distance (normalized) to calculate the distance between names (street, bus station).</p></div>
<div class="paragraph"><p>Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.</p></div></section>
<section id="_levenshtien_on_data"><h2>Levenshtien On Data</h2><div class="imageblock" style=""><img src="../images/lev-hist.png" alt="lev hist"></div></section>
<section><section id="_improve_the_prediction"><h2>Improve the prediction</h2><div class="imageblock" style=""><img src="../images/better.gif" alt="better" width="70%"></div></section><section id="_these_are_not_the_droids_you_are_looking_for_2"><h2>These are not the droids you are looking for</h2><div class="paragraph"><p>We will use Levenshtien distance to filter all observations which are not <em>close</em> enough to its reported bus station.</p></div>
<div class="exampleblock"><div class="content"><div class="paragraph"><p>We defined <em>close</em> with Levenshtien distance &lt; <code>0.5</code>.</p></div></div></div></section><section id="_results"><h2>Results</h2><table class="tableblock frame-all grid-all" style="width:70%"><caption class="title">Table 1. MSE Comparsion (Km<sup>2</sup>)</caption><colgroup><col style="width:50%"><col style="width:50%"></colgroup><thead><tr><th class="tableblock halign-left valign-top">Task 3</th><th class="tableblock halign-left valign-top">Task 4</th></tr><tbody><tr><td class="tableblock halign-left valign-top"><p class="tableblock">0.10125</p></td><td class="tableblock halign-left valign-top"><p class="tableblock"><em>0.2739</em></p></td></tr></table></section></section>
<section><section id="_textual_analysis"><h2>Textual Analysis</h2><div class="imageblock" style=""><img src="../images/word.gif" alt="word" width="80%"></div></section><section id="_name_vs_location"><h2>Name vs. Location</h2><div class="paragraph"><p>Following our prediction task, we were interested in the relation between the textual &amp; spatial distance.</p></div>
<div class="imageblock" style=""><img src="../images/analysis1.png" alt="analysis1"></div>
<aside class="notes"><div class="paragraph"><p>We computed the Levenshtien distance &amp; hoversine distance from a between all bus stops (to all bus stops).<br>
To visualize it, we will present a scatter plot for bus stop <code>7207</code></p></div></aside></section><section id="_gaeilge_vs_english_names"><h2>Gaeilge vs. English names</h2><div class="paragraph"><p>Following our article presentation (GNMT), we were interested wether bus stations names have some similarity between English &amp; Gaeilge (Irish).</p></div>
<div class="imageblock" style=""><img src="../images/analysis2.png" alt="analysis2"></div>
<aside class="notes"><div class="paragraph"><p>We were able to compute a confusion matrix to represent the Levenshtien similarity (normalized distance) between Gaeilge &amp; English station names:</p></div></aside></section></section>
<section id="_questions"><h2>Questions?</h2><div class="imageblock" style=""><img src="../images/que.gif" alt="que" width="70%"></div></section></div></div><script src="node_modules/reveal.js/lib/js/head.min.js"></script><script src="node_modules/reveal.js/js/reveal.js"></script><script>Array.prototype.slice.call(document.querySelectorAll('.slides section')).forEach(function(slide) {
  if (slide.getAttribute('data-background-color')) return;
  // user needs to explicitly say he wants CSS color to override otherwise we might break custom css or theme (#226)
  if (!(slide.classList.contains('canvas') || slide.classList.contains('background'))) return;
  var bgColor = getComputedStyle(slide).backgroundColor;
  if (bgColor !== 'rgba(0, 0, 0, 0)' && bgColor !== 'transparent') {
    slide.setAttribute('data-background-color', bgColor);
    slide.style.backgroundColor = 'transparent';
  }
})

// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display presentation control arrows
  controls: true,
  // Help the user learn the controls by providing hints, for example by
  // bouncing the down arrow when they first encounter a vertical slide
  controlsTutorial: true,
  // Determines where controls appear, "edges" or "bottom-right"
  controlsLayout: 'bottom-right',
  // Visibility rule for backwards navigation arrows; "faded", "hidden"
  // or "visible"
  controlsBackArrows: 'faded',
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: 'true',
  // Control which views the slide number displays on
  showSlideNumber: 'all',
  // Push each slide change to the browser history
  history: true,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Randomizes the order of slides each time the presentation loads
  shuffle: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags whether to include the current fragment in the URL,
  // so that reloading brings you to the same fragment position
  fragmentInURL: false,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Flags if we should show a help overlay when the questionmark
  // key is pressed
  help: true,
  // Flags if speaker notes should be visible to all viewers
  showNotes: false,
  // Global override for autolaying embedded media (video/audio/iframe)
  // - null: Media will only autoplay if data-autoplay is present
  // - true: All media will autoplay, regardless of individual setting
  // - false: No media will autoplay, regardless of individual setting
  autoPlayMedia: null,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Use this method for navigation when auto-sliding
  autoSlideMethod: Reveal.navigateNext,
  // Specify the average time in seconds that you think you will spend
  // presenting each slide. This is used to show a pacing timer in the
  // speaker view
  defaultTiming: 120,
  // Enable slide navigation via mouse wheel
  mouseWheel: true,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  // Add `data-preview-link` and `data-preview-link="false"` to customise each link
  // individually
  previewLinks: false,
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: 'default',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'default',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',
  // Number of pixels to move the parallax background per slide
  // - Calculated automatically unless specified
  // - Set to 0 to disable movement along an axis
  parallaxBackgroundHorizontal: null,
  parallaxBackgroundVertical: null,
  // The display mode that will be used to show slides
  display: 'block',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'node_modules/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      
      { src: 'node_modules/reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'node_modules/reveal.js/plugin/notes/notes.js', async: true },
      
      
      
      
  ],

  

});</script></body></html>